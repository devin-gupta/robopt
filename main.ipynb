{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Bidding (Baselines)\n",
    "\n",
    "In this walkthrough, we'll provide a brief example of how to use the custom bidding environment, as well as implementing some baselines. \n",
    "\n",
    "### Custom Environment Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gymnasium as gym\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "%load_ext tensorboard\n",
    "\n",
    "# stable baselines\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# custom environment\n",
    "from envs.bidding import BiddingEnv\n",
    "\n",
    "env = BiddingEnv()\n",
    "\n",
    "env.render() # choose from verbose, bids, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "\n",
      "Robots:\n",
      "  Robot 1: Robot at (5, 6) with type B-navbot\n",
      "  Robot 2: Robot at (1, 1) with type B-navbot\n",
      "  Robot 3: Robot at (5, 9) with type A-humanbot\n",
      "  Robot 4: Robot at (7, 0) with type C-embedbot\n",
      "  Robot 5: Robot at (2, 5) with type B-navbot\n",
      "  Robot 6: Robot at (2, 4) with type A-humanbot\n",
      "  Robot 7: Robot at (9, 3) with type C-embedbot\n",
      "  Robot 8: Robot at (5, 1) with type A-humanbot\n",
      "  Robot 9: Robot at (5, 6) with type C-embedbot\n",
      "\n",
      "Tasks:\n",
      "  Task 1: Task at (6, 9) with prize 99 and type B-transport\n",
      "  Task 2: Task at (0, 7) with prize 54 and type A-manipulation\n",
      "  Task 3: Task at (2, 0) with prize 48 and type B-transport\n",
      "  Task 4: Task at (7, 4) with prize 16 and type A-manipulation\n",
      "  Task 5: Task at (7, 0) with prize 10 and type A-manipulation\n",
      "  Task 6: Task at (7, 4) with prize 70 and type B-transport\n",
      "\n",
      "Bidding Matrix:\n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   Task 1 │   Task 2 │   Task 3 │   Task 4 │   Task 5 │   Task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "Step: 1\n",
      "\n",
      "Robots:\n",
      "  Robot 1: Robot at (5, 6) with type B-navbot\n",
      "  Robot 2: Robot at (1, 1) with type B-navbot\n",
      "  Robot 3: Robot at (5, 9) with type A-humanbot\n",
      "  Robot 4: Robot at (7, 0) with type C-embedbot\n",
      "  Robot 5: Robot at (2, 5) with type B-navbot\n",
      "  Robot 6: Robot at (2, 4) with type A-humanbot\n",
      "  Robot 7: Robot at (9, 3) with type C-embedbot\n",
      "  Robot 8: Robot at (5, 1) with type A-humanbot\n",
      "  Robot 9: Robot at (5, 6) with type C-embedbot\n",
      "\n",
      "Tasks:\n",
      "  Task 1: Task at (6, 9) with prize 99 and type B-transport\n",
      "  Task 2: Task at (0, 7) with prize 54 and type A-manipulation\n",
      "  Task 3: Task at (2, 0) with prize 48 and type B-transport\n",
      "  Task 4: Task at (7, 4) with prize 16 and type A-manipulation\n",
      "  Task 5: Task at (7, 0) with prize 10 and type A-manipulation\n",
      "  Task 6: Task at (7, 4) with prize 70 and type B-transport\n",
      "\n",
      "Bidding Matrix:\n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   Task 1 │   Task 2 │   Task 3 │   Task 4 │   Task 5 │   Task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        5 │        8 │        5 │        2 │        6 │        4 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        9 │        4 │        5 │        7 │       10 │        4 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        8 │        7 │        1 │        8 │        5 │        2 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        4 │        8 │        7 │        0 │        8 │        1 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        6 │        1 │        6 │        8 │        0 │        7 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        6 │        7 │        5 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        9 │        4 │        0 │        3 │        5 │       10 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        7 │        0 │        7 │        6 │        6 │        2 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        6 │        4 │        0 │        5 │        0 │        7 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "\n",
      " Step 1 with reward = 502.1714389055808\n",
      "Step: 1\n",
      "\n",
      "Robots:\n",
      "  Robot 1: Robot at (5, 6) with type B-navbot\n",
      "  Robot 2: Robot at (1, 1) with type B-navbot\n",
      "  Robot 3: Robot at (5, 9) with type A-humanbot\n",
      "  Robot 4: Robot at (7, 0) with type C-embedbot\n",
      "  Robot 5: Robot at (2, 5) with type B-navbot\n",
      "  Robot 6: Robot at (2, 4) with type A-humanbot\n",
      "  Robot 7: Robot at (9, 3) with type C-embedbot\n",
      "  Robot 8: Robot at (5, 1) with type A-humanbot\n",
      "  Robot 9: Robot at (5, 6) with type C-embedbot\n",
      "\n",
      "Tasks:\n",
      "  Task 1: Task at (6, 9) with prize 99 and type B-transport\n",
      "  Task 2: Task at (0, 7) with prize 54 and type A-manipulation\n",
      "  Task 3: Task at (2, 0) with prize 48 and type B-transport\n",
      "  Task 4: Task at (7, 4) with prize 16 and type A-manipulation\n",
      "  Task 5: Task at (7, 0) with prize 10 and type A-manipulation\n",
      "  Task 6: Task at (7, 4) with prize 70 and type B-transport\n",
      "\n",
      "Bidding Matrix:\n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   Task 1 │   Task 2 │   Task 3 │   Task 4 │   Task 5 │   Task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        5 │        8 │        5 │        2 │        6 │        4 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        9 │        4 │        5 │        7 │       10 │        4 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        8 │        7 │        1 │        8 │        5 │        2 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        4 │        8 │        7 │        0 │        8 │        1 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        6 │        1 │        6 │        8 │        0 │        7 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        6 │        7 │        5 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        9 │        4 │        0 │        3 │        5 │       10 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        7 │        0 │        7 │        6 │        6 │        2 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        6 │        4 │        0 │        5 │        0 │        7 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "Completed, final reward = 502.1714389055808\n",
      "optimal reward =  537.5428303351414\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "# print('Observation space: \\n', env.observation_space)\n",
    "# print('Action space: \\n', env.action_space)\n",
    "# print('Random Action (Bid Matrix): \\n', env.action_space.sample())\n",
    "# print('Random Observation: \\n', env.observation_space.sample())\n",
    "\n",
    "env.render(mode='human')\n",
    "\n",
    "for step in range(10):\n",
    "    \n",
    "    obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "    env.render(mode='human')\n",
    "    print(f'\\n Step {step + 1} with reward = {reward}')\n",
    "\n",
    "    if done:\n",
    "        env.render(mode='human')\n",
    "        print(\"Completed, final reward =\", reward)\n",
    "        break\n",
    "\n",
    "print('optimal reward = ', env.optimal_reward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking with Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation robot_positions has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation task_positions has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:453: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:464: UserWarning: Your action space has dtype int32, we recommend using np.float32 to avoid cast errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = BiddingEnv()\n",
    "\n",
    "# check stable baselines compatibility\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# tensorboard logging\n",
    "tensorboard_log_dir = \"./runs/baselines/bidding_stable_baselines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for random policy: 49565.61 out of optimal 52959.15\n"
     ]
    }
   ],
   "source": [
    "# 1) baseline random policy\n",
    "class RandomPolicy:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def predict(self, observation):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/random_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate random policy\n",
    "random_policy = RandomPolicy(env.action_space)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward, total_opt_reward = 0, 0\n",
    "\n",
    "action_mean, action_std, rewards = [], [], []\n",
    "\n",
    "for step in range(100):  # 1000 steps for example\n",
    "    action = random_policy.predict(obs)\n",
    "\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_opt_reward += env.optimal_reward()\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "    writer.add_scalar(\"Random_Polcy/OptimalReward\", env.optimal_reward(), step)\n",
    "\n",
    "    action_mean.append(np.mean(action))\n",
    "    action_std.append(np.std(action))\n",
    "    rewards.append(reward)\n",
    "\n",
    "    # print('avg bid of ', np.mean(action), ' with std of ', np.std(action), ' gave reward of ', reward)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for random policy: {round(total_reward, 2)} out of optimal {round(total_opt_reward, 2)}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./runs/baselines/sb3_ppo/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 497      |\n",
      "| time/              |          |\n",
      "|    fps             | 3285     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 503         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2476        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019647548 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | -0.000392   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+05    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.7e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 501         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2392        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021558855 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.000602    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+05    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0625     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.56e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2348        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021730732 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.000198    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+05    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0637     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.48e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2336        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020848293 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 6.94e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+05    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0659     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.44e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 516         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020929985 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 4.95e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+05    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0656     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.36e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 483         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2307        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022121303 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 3.82e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+05    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0672     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.31e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 531         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2305        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021384401 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 1.84e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+05    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0662     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.27e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 504         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2303        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022674028 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 1.23e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+05    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0695     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 2.2e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 520         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2273        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023296837 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 1.04e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+05    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0714     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 2.16e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 511         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2271        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023025855 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 1.25e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+05    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0683     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 2.13e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 515         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2265        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025471706 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 6.32e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+05    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0733     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 2.04e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 508        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2260       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02532994 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 4.41e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.05e+05   |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.074     |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.99e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 519         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2247        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026575262 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 4.11e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.57e+04    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0731     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 1.96e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 521         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2252        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024645777 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 3.99e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.08e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0745     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 1.85e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2254        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024963751 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 2.26e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+05    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0743     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 1.86e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 498         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2250        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026395066 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 2.44e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.1e+04     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0785     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 1.78e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2248        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025421582 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 2.03e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.72e+04    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0781     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 1.76e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 544         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2244        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027433753 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 1.43e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.19e+04    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0775     |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 1.63e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 510        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2237       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02641021 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | 1.85e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.12e+04   |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0791    |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.64e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 508        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2240       |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02743616 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | 9.54e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.19e+04   |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0782    |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 1.63e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 485         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2236        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027698409 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 5.96e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.77e+04    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0779     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.5e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 516         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2237        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029271055 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.13e+04    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0803     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.47e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 495         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2239        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029917372 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 7.15e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0815     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.43e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 531         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2242        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030058093 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.22e+04    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0835     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 1.38e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 487         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2244        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029591585 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 5.96e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.23e+04    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0835     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.39e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 506         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2245        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029063227 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 5.96e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.33e+04    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0804     |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 1.34e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 489         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2245        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026895536 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.21e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0783     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 1.33e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 513         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2246        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029992867 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.72e+04    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0854     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 1.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 518         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2246        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030649733 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.9e+04     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0838     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 1.2e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 514         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2244        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031905398 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.84e+04    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0842     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 1.16e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 503         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2245        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030673318 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.94e+04    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0824     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 1.12e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 512       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2239      |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0325309 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -75.7     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.3e+04   |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.0817   |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 1.08e+05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 502         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2234        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031791307 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.81e+04    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0843     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 1.08e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 485        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2231       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03157319 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.07e+04   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.087     |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.85e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 493        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2219       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03370627 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 2.38e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.53e+04   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.088     |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 9.72e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 521         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2216        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033534408 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+04     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0861     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 9.15e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2217        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031390768 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73e+04    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0816     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 9.36e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 506       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2218      |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0340729 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -75.7     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.75e+04  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0853   |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 8.86e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 498         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2219        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034627967 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.56e+04    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0891     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 8.49e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 509        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2220       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03599541 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.35e+04   |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0889    |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 8.26e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 508        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2221       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03314662 |\n",
      "|    clip_fraction        | 0.404      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.71e+04   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0854    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 7.82e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 522         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2222        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038018458 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.73e+04    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0897     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 7.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 494         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2223        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036216162 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.93e+04    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0904     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 7.34e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 498         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2223        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038928766 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.61e+04    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.09       |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 6.89e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 493         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2224        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037321076 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.78e+04    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.088      |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 6.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 505         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2225        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037031587 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.28e+04    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0884     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 6.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 511         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2220        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042503376 |\n",
      "|    clip_fraction        | 0.447       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06e+04    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0907     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 6.04e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 495         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2221        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038386554 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+04     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0906     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 5.92e+04    |\n",
      "-----------------------------------------\n",
      "Mean reward for PPO: 483.83201049999997, Std: 97.44430199689418\n"
     ]
    }
   ],
   "source": [
    "# 2) baseline ppo policy\n",
    "vec_env = make_vec_env(lambda: BiddingEnv(), n_envs=1) # vectorize env for ppo\n",
    "ppo_model = PPO(\"MultiInputPolicy\", vec_env, verbose=1, tensorboard_log=\"./runs/baselines/sb3_ppo\")\n",
    "ppo_model.learn(total_timesteps=100000)\n",
    "\n",
    "ppo_model.load\n",
    "\n",
    "# evaluate ppo policy\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model, vec_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward for PPO: {mean_reward}, Std: {std_reward}\")\n",
    "\n",
    "# close envs (unnecessary in exisitng close() implementation)\n",
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for heuristic policy: -1777.2110281092396\n"
     ]
    }
   ],
   "source": [
    "# 3) baseline heuristic policy\n",
    "class HeuristicPolicy:\n",
    "    def __init__(self, bidding_matrix):\n",
    "        self.bidding_matrix = bidding_matrix\n",
    "\n",
    "    def predict(self, observation):\n",
    "        # given prize range is (0, 4), always bid 2\n",
    "        return np.ones(self.bidding_matrix.shape) * 1\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/heuristic_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate heuristic policy\n",
    "heuristic_policy = HeuristicPolicy(env.bidding_matrix)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):  # 1000 steps for example\n",
    "    action = heuristic_policy.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for heuristic policy: {total_reward}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
