{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Bidding (Baselines)\n",
    "\n",
    "In this walkthrough, we'll provide a brief example of how to use the custom bidding environment, as well as implementing some baselines. \n",
    "\n",
    "### Custom Environment Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "\n",
      "Robots:\n",
      "  Robot 1: Robot at (5, 0) with type navbot\n",
      "  Robot 2: Robot at (5, 1) with type embedbot\n",
      "  Robot 3: Robot at (2, 6) with type humanbot\n",
      "  Robot 4: Robot at (1, 4) with type embedbot\n",
      "  Robot 5: Robot at (8, 6) with type humanbot\n",
      "  Robot 6: Robot at (1, 3) with type navbot\n",
      "  Robot 7: Robot at (3, 0) with type humanbot\n",
      "  Robot 8: Robot at (1, 0) with type embedbot\n",
      "  Robot 9: Robot at (6, 7) with type embedbot\n",
      "\n",
      "Tasks:\n",
      "  Task 1: Task at (4, 5) with prize 2 and type transport\n",
      "  Task 2: Task at (1, 0) with prize 1 and type transport\n",
      "  Task 3: Task at (0, 9) with prize 3 and type manipulation\n",
      "  Task 4: Task at (3, 1) with prize 2 and type specialty\n",
      "  Task 5: Task at (3, 1) with prize 3 and type manipulation\n",
      "  Task 6: Task at (1, 7) with prize 2 and type transport\n",
      "\n",
      "Bidding Matrix:\n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   Task 1 │   Task 2 │   Task 3 │   Task 4 │   Task 5 │   Task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import gymnasium as gym\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "%load_ext tensorboard\n",
    "\n",
    "# stable baselines\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# custom environment\n",
    "from envs.bidding_v2 import BiddingEnv\n",
    "\n",
    "env = BiddingEnv()\n",
    "\n",
    "env.render(mode='verbose') # choose from verbose, bids, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: \n",
      " Dict('robot_0': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_1': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_2': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_3': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_4': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_5': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_6': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_7': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)), 'robot_8': Dict('bidding_matrix': Box(0, 10, (9, 6), int8), 'self_state': Box(0, [10 10  2], (3,), int8)))\n",
      "Action space: \n",
      " Box(0, 10, (9, 6), int8)\n",
      "Random Action (Bid Matrix): \n",
      " [[ 1  4  4  4  6 10]\n",
      " [ 8  7 10  1  6  2]\n",
      " [ 5  2  1  8  0  9]\n",
      " [ 7  9  4  7  2  7]\n",
      " [ 4  6 10  5  4  2]\n",
      " [ 6  5  0  4 10  3]\n",
      " [ 9  1  7  6  2  3]\n",
      " [ 9  2  4  9  2 10]\n",
      " [ 6  2  0  6 10  4]]\n",
      "\n",
      " Step 1 with reward = -0.045955673485829254\n",
      "\n",
      " Step 2 with reward = -0.19325729976323197\n",
      "\n",
      " Step 3 with reward = -0.10340951315094624\n",
      "\n",
      " Step 4 with reward = -0.1784831336699341\n",
      "\n",
      " Step 5 with reward = -0.05884111014803042\n",
      "\n",
      " Step 6 with reward = -0.2982730677620918\n",
      "\n",
      " Step 7 with reward = -0.35890241451765104\n",
      "\n",
      " Step 8 with reward = -0.18397159916811257\n",
      "\n",
      " Step 9 with reward = -0.27770662290683784\n",
      "\n",
      " Step 10 with reward = -9.306124150805633\n",
      "Step: 10\n",
      "Robot at (3, 8) with type embedbot\n",
      "Robot at (7, 6) with type embedbot\n",
      "Robot at (8, 1) with type navbot\n",
      "Robot at (4, 8) with type humanbot\n",
      "Robot at (2, 3) with type humanbot\n",
      "Robot at (0, 6) with type embedbot\n",
      "Robot at (4, 4) with type embedbot\n",
      "Robot at (7, 9) with type navbot\n",
      "Robot at (0, 2) with type navbot\n",
      "\n",
      "Task at (0, 4) with prize 2 and type transport\n",
      "Task at (5, 3) with prize 1 and type manipulation\n",
      "Task at (6, 4) with prize 3 and type transport\n",
      "Task at (7, 3) with prize 1 and type specialty\n",
      "Task at (8, 9) with prize 3 and type specialty\n",
      "Task at (7, 5) with prize 1 and type transport\n",
      "\n",
      "Bidding Matrix: \n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   task 1 │   task 2 │   task 3 │   task 4 │   task 5 │   task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        1 │        7 │        5 │        4 │        1 │        8 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        1 │        0 │        8 │        6 │       10 │        9 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        3 │        6 │       10 │       10 │        9 │        1 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        1 │        4 │       10 │        1 │        1 │        7 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        1 │        3 │        8 │        4 │        6 │        1 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        7 │        4 │        0 │        0 │        9 │       10 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│       10 │        0 │        4 │        0 │        0 │       10 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        1 │        8 │        8 │        8 │        2 │        1 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        1 │        5 │        2 │        3 │        0 │        0 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "Completed, final reward = -9.306124150805633\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "print('Observation space: \\n', env.observation_space)\n",
    "print('Action space: \\n', env.action_space)\n",
    "print('Random Action (Bid Matrix): \\n', env.action_space.sample())\n",
    "\n",
    "for step in range(10):\n",
    "    \n",
    "    obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "    print(f'\\n Step {step + 1} with reward = {reward}')\n",
    "\n",
    "    if done:\n",
    "        env.render(mode='verbose')\n",
    "        print(\"Completed, final reward =\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking with Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BiddingEnv()\n",
    "\n",
    "# check stable baselines compatibility\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# tensorboard logging\n",
    "tensorboard_log_dir = \"./runs/baselines/bidding_stable_baselines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for random policy: -1719.644727906495\n"
     ]
    }
   ],
   "source": [
    "# 1) baseline random policy\n",
    "class RandomPolicy:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def predict(self, observation):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/random_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate random policy\n",
    "random_policy = RandomPolicy(env.action_space)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward = 0\n",
    "\n",
    "for step in range(1000):  # 1000 steps for example\n",
    "    action = random_policy.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for random policy: {total_reward}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./runs/baselines/sb3_ppo/PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | -16.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 3549     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2610       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10157428 |\n",
      "|    clip_fraction        | 0.49       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.7      |\n",
      "|    explained_variance   | -0.0128    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.2       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0939    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 77.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -13.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2442       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12352804 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | -0.0047    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31.2       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0796    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 68.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2358       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06283329 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | -0.000778  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.1       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.106     |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 55.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -14.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2168       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08389276 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.5      |\n",
      "|    explained_variance   | -0.00848   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0942    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 62.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -15.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2078        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049003057 |\n",
      "|    clip_fraction        | 0.503       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0966     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -16.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2088        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059479848 |\n",
      "|    clip_fraction        | 0.53        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0971     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -17.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2090        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.116204515 |\n",
      "|    clip_fraction        | 0.623       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | -0.0247     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0862     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -17.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2083       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07942322 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.5      |\n",
      "|    explained_variance   | -0.0071    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0971    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 60.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -15.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2078        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070510864 |\n",
      "|    clip_fraction        | 0.591       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | -0.00106    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0965     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2009       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07189429 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.4      |\n",
      "|    explained_variance   | -0.0303    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.3       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0982    |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 54.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -14         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2018        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.120024726 |\n",
      "|    clip_fraction        | 0.636       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | -0.018      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0918     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2014       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08560641 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | -0.0121    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22         |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.1       |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 54.9       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10        |\n",
      "|    ep_rew_mean          | -14.9     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2024      |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1148862 |\n",
      "|    clip_fraction        | 0.666     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -76.3     |\n",
      "|    explained_variance   | -0.0233   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 20.9      |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -0.0912   |\n",
      "|    std                  | 0.994     |\n",
      "|    value_loss           | 49.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -14.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1973        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099061936 |\n",
      "|    clip_fraction        | 0.632       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | -0.0151     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0993     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1961       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12907228 |\n",
      "|    clip_fraction        | 0.638      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | -0.0234    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0904    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 45.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1969       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10929367 |\n",
      "|    clip_fraction        | 0.642      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | -0.00842   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.9       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0869    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 54         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1956       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13774532 |\n",
      "|    clip_fraction        | 0.674      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | -0.0208    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0845    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 54.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -16.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1930        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098291144 |\n",
      "|    clip_fraction        | 0.614       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0935     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1933       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12703541 |\n",
      "|    clip_fraction        | 0.657      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | -0.0234    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.2       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0896    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 50.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1943       |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18732822 |\n",
      "|    clip_fraction        | 0.696      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | -0.0218    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0764    |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1951       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20080638 |\n",
      "|    clip_fraction        | 0.721      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | -0.0261    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.2       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0725    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 49.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1954       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18817559 |\n",
      "|    clip_fraction        | 0.719      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | -0.021     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31.2       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0696    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 56         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1962       |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20309329 |\n",
      "|    clip_fraction        | 0.715      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | -0.0158    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0809    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 50.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1968       |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14193624 |\n",
      "|    clip_fraction        | 0.694      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0132    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34         |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0914    |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 56.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -17.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1975       |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13421574 |\n",
      "|    clip_fraction        | 0.672      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0161    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0938    |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 59.7       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10        |\n",
      "|    ep_rew_mean          | -14.3     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1974      |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1644409 |\n",
      "|    clip_fraction        | 0.697     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -76       |\n",
      "|    explained_variance   | -0.0266   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 28        |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.0812   |\n",
      "|    std                  | 0.989     |\n",
      "|    value_loss           | 62.5      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -17.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1980       |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14848861 |\n",
      "|    clip_fraction        | 0.691      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0194    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.5       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0864    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 62.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1985       |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23686707 |\n",
      "|    clip_fraction        | 0.727      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0394    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.7       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 54         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1990       |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19355807 |\n",
      "|    clip_fraction        | 0.721      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0136    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0725    |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 60.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1991       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17736435 |\n",
      "|    clip_fraction        | 0.707      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | -0.0181    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 55.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1996       |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18880941 |\n",
      "|    clip_fraction        | 0.719      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | -0.0188    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0788    |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 48.6       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 10       |\n",
      "|    ep_rew_mean          | -14.8    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1994     |\n",
      "|    iterations           | 33       |\n",
      "|    time_elapsed         | 33       |\n",
      "|    total_timesteps      | 67584    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.179046 |\n",
      "|    clip_fraction        | 0.725    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -75.9    |\n",
      "|    explained_variance   | -0.0117  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 29.3     |\n",
      "|    n_updates            | 320      |\n",
      "|    policy_gradient_loss | -0.0565  |\n",
      "|    std                  | 0.987    |\n",
      "|    value_loss           | 57.1     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1997       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24712089 |\n",
      "|    clip_fraction        | 0.725      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | -0.0202    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0655    |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 56.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -14.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2002       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23902932 |\n",
      "|    clip_fraction        | 0.722      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | -0.0187    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0698    |\n",
      "|    std                  | 0.987      |\n",
      "|    value_loss           | 67.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -13.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2006       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30082852 |\n",
      "|    clip_fraction        | 0.771      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.0226    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27.8       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0481    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 55         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2010       |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20247993 |\n",
      "|    clip_fraction        | 0.746      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.00351   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.064     |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 51.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2013       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22225094 |\n",
      "|    clip_fraction        | 0.699      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.0335    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 53.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2014       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24783018 |\n",
      "|    clip_fraction        | 0.768      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.00773   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.6       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 53.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2015       |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13633761 |\n",
      "|    clip_fraction        | 0.684      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.0065    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.4       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0833    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 65.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2015       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14557076 |\n",
      "|    clip_fraction        | 0.675      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.0234    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.3       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0871    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 62.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -15.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2015       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19279996 |\n",
      "|    clip_fraction        | 0.71       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.0258    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.6       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0699    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 59.4       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10        |\n",
      "|    ep_rew_mean          | -16       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2018      |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1979384 |\n",
      "|    clip_fraction        | 0.716     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -75.8     |\n",
      "|    explained_variance   | -0.0132   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 25.6      |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0836   |\n",
      "|    std                  | 0.986     |\n",
      "|    value_loss           | 53.1      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10        |\n",
      "|    ep_rew_mean          | -14.1     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2021      |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2134772 |\n",
      "|    clip_fraction        | 0.735     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -75.8     |\n",
      "|    explained_variance   | -0.0134   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 26.9      |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -0.0649   |\n",
      "|    std                  | 0.985     |\n",
      "|    value_loss           | 51.9      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2022       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19916388 |\n",
      "|    clip_fraction        | 0.718      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.0213    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0762    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 50.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2022       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15999106 |\n",
      "|    clip_fraction        | 0.699      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.2       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0856    |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 73.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -12.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2025       |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21301477 |\n",
      "|    clip_fraction        | 0.726      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.017     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.3       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0721    |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 51.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2023       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19548574 |\n",
      "|    clip_fraction        | 0.704      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | -0.0136    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0741    |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 52.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -16        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2024       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25753844 |\n",
      "|    clip_fraction        | 0.75       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | -0.0188    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.4       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0557    |\n",
      "|    std                  | 0.986      |\n",
      "|    value_loss           | 54.4       |\n",
      "----------------------------------------\n",
      "Mean reward for PPO: -20.968082700000004, Std: 8.901254273863028\n"
     ]
    }
   ],
   "source": [
    "# 2) baseline ppo policy\n",
    "vec_env = make_vec_env(lambda: BiddingEnv(), n_envs=1) # vectorize env for ppo\n",
    "ppo_model = PPO(\"MultiInputPolicy\", vec_env, verbose=1, tensorboard_log=\"./runs/baselines/sb3_ppo\")\n",
    "ppo_model.learn(total_timesteps=100000)\n",
    "\n",
    "# evaluate ppo policy\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model, vec_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward for PPO: {mean_reward}, Std: {std_reward}\")\n",
    "\n",
    "# close envs (unnecessary in exisitng close() implementation)\n",
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for heuristic policy: -1777.2110281092396\n"
     ]
    }
   ],
   "source": [
    "# 3) baseline heuristic policy\n",
    "class HeuristicPolicy:\n",
    "    def __init__(self, bidding_matrix):\n",
    "        self.bidding_matrix = bidding_matrix\n",
    "\n",
    "    def predict(self, observation):\n",
    "        # given prize range is (0, 4), always bid 2\n",
    "        return np.ones(self.bidding_matrix.shape) * 1\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/heuristic_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate heuristic policy\n",
    "heuristic_policy = HeuristicPolicy(env.bidding_matrix)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):  # 1000 steps for example\n",
    "    action = heuristic_policy.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for heuristic policy: {total_reward}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
