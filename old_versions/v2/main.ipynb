{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Bidding (Baselines)\n",
    "\n",
    "In this walkthrough, we'll provide a brief example of how to use the custom bidding environment, as well as implementing some baselines. \n",
    "\n",
    "### Custom Environment Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gymnasium as gym\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "%load_ext tensorboard\n",
    "\n",
    "# stable baselines\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# custom environment\n",
    "from envs.bidding import BiddingEnv\n",
    "\n",
    "env = BiddingEnv()\n",
    "\n",
    "env.render() # choose from human, human_verbose, rgb_array, ansi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "\n",
      "Robots:\n",
      "  Robot 1: Robot at (8, 9) with type A-humanbot\n",
      "  Robot 2: Robot at (9, 5) with type A-humanbot\n",
      "  Robot 3: Robot at (3, 4) with type A-humanbot\n",
      "  Robot 4: Robot at (7, 4) with type C-embedbot\n",
      "  Robot 5: Robot at (6, 3) with type C-embedbot\n",
      "  Robot 6: Robot at (2, 6) with type B-navbot\n",
      "  Robot 7: Robot at (0, 0) with type B-navbot\n",
      "  Robot 8: Robot at (8, 7) with type C-embedbot\n",
      "  Robot 9: Robot at (7, 9) with type A-humanbot\n",
      "\n",
      "Tasks:\n",
      "  Task 1: Task at (1, 4) with prize 5 and type B-transport\n",
      "  Task 2: Task at (1, 3) with prize 11 and type B-transport\n",
      "  Task 3: Task at (8, 9) with prize 53 and type B-transport\n",
      "  Task 4: Task at (6, 7) with prize 67 and type B-transport\n",
      "  Task 5: Task at (1, 2) with prize 72 and type A-manipulation\n",
      "  Task 6: Task at (2, 3) with prize 51 and type B-transport\n",
      "\n",
      "Bidding Matrix:\n",
      "╒══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│   Task 1 │   Task 2 │   Task 3 │   Task 4 │   Task 5 │   Task 6 │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "╘══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "Completed, final reward = 440.28280251717985\n",
      "Optimal reward =  465.6896297341106\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "# print('Observation space: \\n', env.observation_space)\n",
    "# print('Action space: \\n', env.action_space)\n",
    "# print('Random Action (Bid Matrix): \\n', env.action_space.sample())\n",
    "# print('Random Observation: \\n', env.observation_space.sample())\n",
    "\n",
    "env.render(mode='human_verbose')\n",
    "\n",
    "# sample random action\n",
    "obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "print(\"Completed, final reward =\", reward)\n",
    "print('Optimal reward = ', env.optimal_reward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking with Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n",
      "bidding matrix shape (9, 6)  and action shape  (9, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation robot_positions has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation task_positions has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:453: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n",
      "/Users/devg/robopt/.venv/lib/python3.11/site-packages/stable_baselines3/common/env_checker.py:464: UserWarning: Your action space has dtype int32, we recommend using np.float32 to avoid cast errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = BiddingEnv()\n",
    "\n",
    "# check stable baselines compatibility\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# tensorboard logging\n",
    "tensorboard_log_dir = \"./runs/baselines/bidding_stable_baselines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for random policy: 49613.31 out of optimal 52959.15\n"
     ]
    }
   ],
   "source": [
    "# 1) baseline random policy\n",
    "class RandomPolicy:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def predict(self, observation):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/random_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate random policy\n",
    "random_policy = RandomPolicy(env.action_space)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward, total_opt_reward = 0, 0\n",
    "\n",
    "action_mean, action_std, rewards = [], [], []\n",
    "\n",
    "for step in range(100):  # 1000 steps for example\n",
    "    action = random_policy.predict(obs)\n",
    "\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_opt_reward += env.optimal_reward()\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "    writer.add_scalar(\"Random_Polcy/OptimalReward\", env.optimal_reward(), step)\n",
    "\n",
    "    action_mean.append(np.mean(action))\n",
    "    action_std.append(np.std(action))\n",
    "    rewards.append(reward)\n",
    "\n",
    "    # print('avg bid of ', np.mean(action), ' with std of ', np.std(action), ' gave reward of ', reward)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for random policy: {round(total_reward, 2)} out of optimal {round(total_opt_reward, 2)}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./runs/baselines/sb3_ppo/PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 496      |\n",
      "| time/              |          |\n",
      "|    fps             | 3217     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 506         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2461        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018525261 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.00072     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+05    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0559     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.69e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020788569 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.000472    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+05    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.059      |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.56e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2248        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021987928 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.000149    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+05    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0638     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.48e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2205        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023075677 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 5.31e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+05    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0642     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.44e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 517        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2190       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02026289 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.5      |\n",
      "|    explained_variance   | 3.31e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.12e+05   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0627    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 2.36e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 485         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2150        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021710556 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 2.84e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+05    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 2.31e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 531         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2147        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022847993 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 1.72e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+05    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0638     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.28e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 502         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020986782 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 1.08e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+05    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0645     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 2.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 519         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2133        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021676455 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 7.27e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+05    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0666     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.16e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022078503 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 1.2e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+05    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.065      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.13e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 516         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2136        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023941943 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 4.95e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+05    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0679     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.04e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 510         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2134        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024390757 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 4.05e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+05    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0716     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 1.99e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 522         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2140        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024324752 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 3.58e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.47e+04    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0704     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 1.97e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 520         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2146        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025554936 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 2.8e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.15e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0719     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 1.86e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2149        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024092134 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 1.55e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+05    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0723     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.86e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2151        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026632322 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 1.97e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.17e+04    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0719     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.78e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2145        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025619108 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 1.37e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63e+04    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0735     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 1.77e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 543         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2143        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027125578 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 1.01e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.07e+04    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0745     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 1.63e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 509        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2143       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02829063 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | 1.61e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.06e+04   |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 1.63e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 509         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2145        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025148723 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 7.15e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.34e+04    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0742     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.63e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 487        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2147       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02694177 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.5      |\n",
      "|    explained_variance   | 5.96e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.76e+04   |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0773    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 1.51e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 516         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2150        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028122399 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 7.15e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.2e+04     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0766     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.47e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 494         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2149        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028723234 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 4.77e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.48e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0778     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.43e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 532         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2149        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030208476 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 5.96e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.2e+04     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0811     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.38e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 489         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2119        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028158752 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.34e+04    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0782     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.39e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2103        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027157366 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.4e+04     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0799     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.34e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 489         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2107        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028721096 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.31e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0804     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 1.34e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2106        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029970204 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.66e+04    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0801     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 1.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 517         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2109        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029811822 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.89e+04    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0823     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 1.2e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 513         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2112        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031521607 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.81e+04    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0839     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 1.16e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031831853 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.94e+04    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0829     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 1.13e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 513        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2113       |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03168653 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 3.58e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.31e+04   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0841    |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 1.09e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 504        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2112       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03009755 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 2.38e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.77e+04   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0842    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 1.08e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 487         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2107        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032546017 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13e+04    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0853     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 9.88e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 490        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2098       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03071409 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.53e+04   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0834    |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 9.74e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 522         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2089        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032171637 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.41e+04    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0817     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 9.19e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 506       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2088      |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313589 |\n",
      "|    clip_fraction        | 0.357     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -76.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.71e+04  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -0.083    |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 9.41e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 506       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2087      |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0355434 |\n",
      "|    clip_fraction        | 0.397     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -76.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.81e+04  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0862   |\n",
      "|    std                  | 0.991     |\n",
      "|    value_loss           | 8.91e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 494         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2086        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033401567 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.59e+04    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0859     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 8.54e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 510         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2086        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036225542 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.35e+04    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0895     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 8.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 508        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2087       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03401747 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.81e+04   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0837    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 7.87e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 522        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2087       |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03258416 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.85e+04   |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0826    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 7.46e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 494        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2089       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03730771 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.98e+04   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0877    |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 7.38e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 501         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2092        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036897287 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+04    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.088      |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 6.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 496        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2093       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03878872 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.79e+04   |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0913    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 6.57e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 501        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2082       |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03725691 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.29e+04   |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0892    |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 6.4e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 510        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2073       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03882801 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.89e+04   |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0904    |\n",
      "|    std                  | 0.99       |\n",
      "|    value_loss           | 6.09e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 492         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2067        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039972156 |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.85e+04    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0906     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 5.92e+04    |\n",
      "-----------------------------------------\n",
      "Mean reward for PPO: 483.6162451, Std: 101.90591357888258\n"
     ]
    }
   ],
   "source": [
    "# 2) baseline ppo policy\n",
    "vec_env = make_vec_env(lambda: BiddingEnv(), n_envs=1) # vectorize env for ppo\n",
    "ppo_model = PPO(\"MultiInputPolicy\", vec_env, verbose=1, tensorboard_log=\"./runs/baselines/sb3_ppo\")\n",
    "ppo_model.learn(total_timesteps=100000)\n",
    "\n",
    "ppo_model.load\n",
    "\n",
    "# evaluate ppo policy\n",
    "mean_reward, std_reward = evaluate_policy(ppo_model, vec_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward for PPO: {mean_reward}, Std: {std_reward}\")\n",
    "\n",
    "# close envs (unnecessary in exisitng close() implementation)\n",
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for heuristic policy: 502956.06734109914 out of optimal 536528.54\n"
     ]
    }
   ],
   "source": [
    "# 3) baseline heuristic policy\n",
    "class HeuristicPolicy:\n",
    "    def __init__(self, bidding_matrix):\n",
    "        self.bidding_matrix = bidding_matrix\n",
    "\n",
    "    def predict(self, observation):\n",
    "        # given prize range is (0, 100), always bid 50\n",
    "        return np.ones(self.bidding_matrix.shape) * 50\n",
    "\n",
    "# tensorboard random policy\n",
    "log_dir = \"./runs/baselines/heuristic_policy\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# evaluate heuristic policy\n",
    "heuristic_policy = HeuristicPolicy(env.bidding_matrix)\n",
    "obs, _ = env.reset(seed=42)\n",
    "total_reward, total_opt_reward = 0, 0\n",
    "\n",
    "for _ in range(1000):  # 1000 steps for example\n",
    "    action = heuristic_policy.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_opt_reward += env.optimal_reward()\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar(\"Random_Policy/AvgBid\", np.mean(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/StdBid\", np.std(action), step)\n",
    "    writer.add_scalar(\"Random_Policy/Reward\", reward, step)\n",
    "\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "print(f\"Total reward for heuristic policy: {total_reward} out of optimal {round(total_opt_reward, 2)}\")\n",
    "\n",
    "writer.close() # close tensorboard writer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
